#!/usr/local/bin/Rscript

source("scraper.R")
library(rmongodb)

if ( Sys.getenv("CNN_STORAGE") == "REMOTE") {
  mongo <- mongo.create(
    host     = Sys.getenv("MONGO_CNN_HOST"), 
    username = Sys.getenv("MONGO_CNN_USER"), 
    password = Sys.getenv("MONGO_CNN_PASSWORD"), 
    db       = Sys.getenv("MONGO_CNN_DB")
  )
} else {
  mongo <- mongo.create(
    username = Sys.getenv("MONGO_CNN_USER"), 
    password = Sys.getenv("MONGO_CNN_PASSWORD"), 
    db       = Sys.getenv("MONGO_CNN_DB")
  )
}
cnn_collection <- paste(Sys.getenv("MONGO_CNN_DB"), Sys.getenv("MONGO_CNN_COLLECTION"), sep = ".")

`%nin%`      <- Negate(`%in%`)
# recent_time  <- Sys.time() - days(10)
# mongo_select <- mongo.bson.buffer.create()
# invisible(mongo.bson.buffer.start.object(mongo_select, "date"))
# invisible(mongo.bson.buffer.append(mongo_select, "$gte", recent_time))
# invisible(mongo.bson.buffer.finish.object(mongo_select))

recent_stories <- mongo.find.all(mongo, cnn_collection,  
#                                query  = mongo.bson.from.buffer(mongo_select), 
                                 fields = list("_id" = 0, url = 1L)) %>% 
  unlist(use.names = FALSE)

master   <- plyr::ldply(sources, scrapeStories) %>% 
    filter(paste0(cnn, href) %nin% recent_stories)
print(paste(nrow(new_stories), "new articles have been collected from CNN at", Sys.time(), "Scraping now..."))

if (nrow(new_stories) > 0) {
  articles  <- plyr::dlply(master, "href", scrapeArticle)
  articles  <- parseLocations(articles)

  bson_list <- lapply(articles, mongo.bson.from.list)
  mongo.insert.batch(mongo, cnn_collection, bson_list)
  print("Scraping complete and stored.")
}
invisible( mongo.destroy(mongo) )
